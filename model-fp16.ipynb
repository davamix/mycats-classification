{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SeparableConv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from metrics import MCC_binary, MCC_multi\n",
    "\n",
    "import Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable FP16\n",
    "\n",
    "# https://medium.com/@noel_kennedy/how-to-use-half-precision-float16-when-training-on-rtx-cards-with-tensorflow-keras-d4033d59f9e4\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.set_floatx('float16')\n",
    "\n",
    "# default is 1e-7 which is too small for float16.  \n",
    "# Without adjusting the epsilon, we will get NaN predictions because of divide by zero problems\n",
    "K.set_epsilon(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PATHS\n",
    "\n",
    "TRAIN_FOLDER_PATH = './data/train/'\n",
    "VAL_FOLDER_PATH = './data/validation/'\n",
    "TEST_FOLDER_PATH = './data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "\n",
    "learning_rate = 2e-5\n",
    "batch_size = 20\n",
    "num_epochs = 40\n",
    "classes = 2\n",
    "loss = \"categorical_crossentropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image properties\n",
    "\n",
    "img_width = 299\n",
    "img_height = 299\n",
    "img_depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator\n",
    "\n",
    "data_gen = ImageDataGenerator(\n",
    "    rescale = 1 / 255.0,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = \"nearest\"\n",
    ")\n",
    "\n",
    "def get_train_generator(img_height, img_width):\n",
    "    train_generator = data_gen.flow_from_directory(\n",
    "        TRAIN_FOLDER_PATH,\n",
    "        target_size = (img_height, img_width),\n",
    "        color_mode = 'rgb',\n",
    "        batch_size = batch_size,\n",
    "        class_mode = 'categorical',\n",
    "        shuffle = True\n",
    "    )\n",
    "    \n",
    "    return train_generator\n",
    "\n",
    "def get_validation_generator(img_height, img_width):\n",
    "    validation_generator = data_gen.flow_from_directory(\n",
    "        VAL_FOLDER_PATH,\n",
    "        target_size = (img_height, img_width),\n",
    "        color_mode = 'rgb',\n",
    "        batch_size = batch_size,\n",
    "        class_mode = 'categorical',\n",
    "        shuffle = True\n",
    "    )\n",
    "    \n",
    "    return validation_generator\n",
    "\n",
    "def get_test_generator(img_height, img_width):\n",
    "    test_generator = data_gen.flow_from_directory(\n",
    "        TEST_FOLDER_PATH,\n",
    "        target_size = (img_height, img_width),\n",
    "        color_mode='rgb',\n",
    "        batch_size = batch_size,\n",
    "        class_mode = 'categorical',\n",
    "        shuffle = False\n",
    "    )\n",
    "    \n",
    "    return test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "def get_callbacks():\n",
    "    mc = ModelCheckpoint('best_fp16.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "    \n",
    "    return [mc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "def compile_model(model):\n",
    "    opt = SGD(lr = learning_rate)\n",
    "    \n",
    "    model.compile(loss = loss, optimizer = opt, metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "\n",
    "def fit_model(model, train_generator, validation_generator):\n",
    "    history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch = train_generator.n // train_generator.batch_size,\n",
    "        epochs = num_epochs,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = validation_generator.n // validation_generator.batch_size,\n",
    "        use_multiprocessing = False,\n",
    "        callbacks = get_callbacks())\n",
    "    \n",
    "    return history, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "def save_model(model, model_name):\n",
    "    model.save(model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "def evaluate_model(model, validation_generator):\n",
    "    return model.evaluate_generator(validation_generator, steps = validation_generator.n // validation_generator.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "\n",
    "def get_predictions(model, test_generator):\n",
    "    test_generator.reset()\n",
    "    \n",
    "    predIdx = model.predict_generator(test_generator, steps = (test_generator.n // test_generator.batch_size) + 1)\n",
    "    \n",
    "    predIdx = np.argmax(predIdx, axis=1)\n",
    "    \n",
    "    return predIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy and loss\n",
    "\n",
    "def plot_metrics(history):\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='lower right')\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    \n",
    "    # Plot MCC_binary values\n",
    "    #plt.subplot(2,2,3)\n",
    "    #plt.plot(history.history['MCC_binary'])\n",
    "    #plt.plot(history.history['val_MCC_binary'])\n",
    "    #plt.title('model MCC_binary')\n",
    "    #plt.ylabel('MCC_binary')\n",
    "    #plt.xlabel('epoch')\n",
    "    #plt.legend(['train', 'validation'], loc='lower right')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show evaluation metrics\n",
    "\n",
    "def show_eval_metrics(model, metrics):\n",
    "    for idx, m in enumerate(model.metrics_names):\n",
    "        print(\"{}: {:.4f}\".format(m, metrics[idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show test metrics\n",
    "\n",
    "def show_test_metrics(predictions, test_generator):\n",
    "    print(\"## Classification report ##\")\n",
    "    print(classification_report(test_generator.classes, predictions, target_names=test_generator.class_indices.keys()))\n",
    "\n",
    "    cm = confusion_matrix(test_generator.classes, predictions)\n",
    "    \n",
    "    total = sum(sum(cm))\n",
    "    acc = (cm[0,0] + cm[1,1]) / total\n",
    "    sensitivity = cm[0,0] / (cm[0,0] + cm[0,1])\n",
    "    specificity = cm[1,1] / (cm[1,0] + cm[1,1])\n",
    "\n",
    "    print(\"## Other values ##\")\n",
    "    print(\"acc: {:.4f}\".format(acc))\n",
    "    print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
    "    print(\"specificity: {:.4f}\".format(specificity))\n",
    "    print(\"MCC multi: {:.4f}\".format(MCC_multi(cm)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "\n",
    "def plot_confusion_matrix(predictions, test_generator, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    cm = confusion_matrix(test_generator.classes, predictions)\n",
    "    classes = test_generator.class_indices.keys()\n",
    "    \n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 227 images belonging to 2 classes.\n",
      "Found 73 images belonging to 2 classes.\n",
      "Found 47 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create the generators\n",
    "\n",
    "train_generator = get_train_generator(img_height, img_width)\n",
    "validation_generator = get_validation_generator(img_height, img_width)\n",
    "test_generator = get_test_generator(img_height, img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xception model\n",
    "\n",
    "#from tensorflow.keras.applications.xception import Xception\n",
    "\n",
    "#xception_model = Xception(weights='imagenet', include_top=False, input_shape = (img_height, img_width, img_depth))\n",
    "\n",
    "#model = Sequential()\n",
    "#model.add(xception_model)\n",
    "\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(256))\n",
    "#model.add(Activation(\"relu\"))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.4))\n",
    "\n",
    "#model.add(Dense(2))\n",
    "#model.add(Activation(\"softmax\"))\n",
    "\n",
    "#xception_model.trainable = False\n",
    "\n",
    "model = Models.build_xception(img_height, img_width, img_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'get_default_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3dfce83a7e0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_efficientnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~home/work/Models.py\u001b[0m in \u001b[0;36mbuild_efficientnet\u001b[0;34m(height, width, depth, include_top, weights)\u001b[0m\n\u001b[1;32m     31\u001b[0m     efficientnet_model = efn.EfficientNetB0(weights=weights, \n\u001b[1;32m     32\u001b[0m                                             \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                                            input_shape=(height, width, depth))\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/efficientnet/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/efficientnet/model.py\u001b[0m in \u001b[0;36mEfficientNetB0\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                         \u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                         \u001b[0mpooling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpooling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/efficientnet/model.py\u001b[0m in \u001b[0;36mEfficientNet\u001b[0;34m(width_coefficient, depth_coefficient, default_resolution, dropout_rate, drop_connect_rate, depth_divisor, blocks_args, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mimg_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[0;34m(shape, batch_shape, name, dtype, sparse, tensor)\u001b[0m\n\u001b[1;32m    176\u001b[0m                              \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                              \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                              input_tensor=tensor)\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0;31m# Return tensor including _keras_shape and _keras_history.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;31m# Note that in this case train_output and test_output are the same pointer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, batch_size, batch_input_shape, dtype, input_tensor, sparse, name)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'input'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_uid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_uid\u001b[0;34m(prefix)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \"\"\"\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_default_graph'"
     ]
    }
   ],
   "source": [
    "# EfficientNet model\n",
    "\n",
    "#img_width = 224\n",
    "#img_height = 224\n",
    "#model = Models.build_efficientnet(img_height, img_width, img_depth)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "\n",
    "model = compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "history, model = fit_model(model, train_generator, validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "save_model(model, 'fp16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "\n",
    "metrics = evaluate_model(model, validation_generator)\n",
    "show_eval_metrics(model, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot metrics from history\n",
    "\n",
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0821 23:44:34.851506 140616429242176 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('fp16.h5', custom_objects={'MCC_binary':MCC_binary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "\n",
    "predictions = get_predictions(model, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "\n",
    "plot_confusion_matrix(predictions, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Classification report ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Blacky       1.00      0.95      0.97        20\n",
      "       Niche       0.96      1.00      0.98        27\n",
      "\n",
      "    accuracy                           0.98        47\n",
      "   macro avg       0.98      0.97      0.98        47\n",
      "weighted avg       0.98      0.98      0.98        47\n",
      "\n",
      "## Other values ##\n",
      "acc: 0.9787\n",
      "sensitivity: 0.9500\n",
      "specificity: 1.0000\n",
      "MCC multi: 0.9571\n"
     ]
    }
   ],
   "source": [
    "# Show final metrics\n",
    "\n",
    "show_test_metrics(predictions, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
